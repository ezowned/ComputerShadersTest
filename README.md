# Unity3d: сравнение производительности различных типов памяти в вычислительных шейдерах
### Введие
Зачастую для решения какой-либо задачи в режиме реального времени (что крайне важно в играх) мощности одного лишь CPU не достаточно, из-за чего появляется необходимость перенести часть вычислений на GPU. Для решения этой проблемы были придуманы вычислительные шейдеры - программа на си-подобном синтаксисе, вручную запускаемая на видеокарте вне графического конвеера. Движок Unity3d предоставляет 2 класса, обеспечивающих вычисления на gpu - ComputeShader (сама программа, запускаемая на gpu) и ComputeBuffer (буфер данных, используемых для обмена данными между cpu и gpu). Вычислительные шейдеры могут дать ускорение в десятки/сотни раз, однако отсутствие понимания принципов работы памяти видеокарты может значительно уменьшить прирост в производительности. 

## Иерархия памяти 
Подобно cpu, у видеокарты тоже есть регистры, кэш и общая (аналог оперативной памяти).

Размер общей памяти (global memory) варьируется в пределах от нескольких сотен мегабайт до нескольких гигабайт. В этой памяти и располагается тот самый вычислительный буффер (ComputeBuffer), доступ которому на чтение/запись возможен одновременно из любого потока (ядра). Как можно было догадаться, общая память является самой медленной и зачастую является главным барьером производительности.

Кэш у видеокарты не простой: у каждого потокового мультипроцессора (группы потоков) есть своя область более быстрой памяти, разделённой на две части кэш L1 и shared memory. Общий размер варьируется от 48кб до 128кб, при этом кэш и shared memory могут быть поделены в разных пропорциях. К примеру из 60кб половина (30кб) может быть выделена под кэш, а оставшиеся 30кб под shared memory. Отличие между кэшем и разделяемой памятью только в том, что кэш использует видеокарты на своё усмотрение, а разделяемую память вы контролируете вручную. 
Поскольку область разделяемой памяти ограничена потоковым мультипроцессором, буффер будет отдельный для каждой группы потоков (thread group), а не для всех потоков.  

Регистры - расположены в самих ядрах, из-за чего область видимости находится в пределах одного потока. Являются самым быстрым типом памяти. Как правило число ограничено несколькими десятками на поток.

# Ближе к делу
Итак, приступим к сравнению скорости доступа.  
Для этого создадим массив длиной 4096 и для каждого его элемента в вычислительном шейдере запустим цикл из 100к итераций, в котором значение будет увеличиваться на единицу. Размер группы потоков - (64,1,1).   

Поскольку основная цель - сравнить скорость доступа разных типов памяти, а не производительность операций, то в качестве вычислительной нагрузке использована одна из наиболее простых операций - инкремент. 

Объявление буффера с данными:  
```c
RWStructuredBuffer<int> data;
```


В тесте глобальной памяти при каждом инкременте происходит обращение к вычислительному буфферу:   
```c
[numthreads(64,1,1)]
void F0(uint3 id : SV_DispatchThreadID, uint gid : SV_GroupThreadID)
{
	for (int i = 0; i < 100000; ++i) data[id.x] += 1;
}
```


В тесте разделяемой памяти сначала все элементы копируются из основного буфера в разделяемую память, и в цикле при каждом инкременте происходит обращение к этому новому shared буферу:      
```c
groupshared float sharedbuff [64]; //массив для разделяемой памяти - размер соответствует размеру группы потоков

[numthreads(64, 1, 1)]
void F1(uint3 id : SV_DispatchThreadID, uint gid : SV_GroupThreadID)
{
	sharedbuff[gid.x] = data[id.x];
	for (int i = 0; i < 100000; ++i) sharedbuff[gid.x] += 1;
	data[id.x] = sharedbuff[gid.x];
}

```


В случае с регистрами просто объявляем регистр, в котором и будем накапливать сумму:
```c
[numthreads(64, 1, 1)]
void F2(uint3 id : SV_DispatchThreadID, uint gid : SV_GroupThreadID)
{
	int t = data[id.x];
	for (int i = 0; i < 100000; ++i) t += 1; 
	data[id.x] = t;
}
```
Кто-то скажет, что при компиляции цикл может быть оптимизирован в одну операцию - в таком случае давайте добавим ещё одну функцию F3 с циклом из двух итераций. Если компилятор действительно оптимизирует циклы, то ожидаемо увидеть одинаковое время работы для этих двух функций (c относительной погрешностью не более 5-10%):
```c
[numthreads(64, 1, 1)]
void F3(uint3 id : SV_DispatchThreadID, uint gid : SV_GroupThreadID)
{
	int t = data[id.x];
	for (int i = 0; i < 2; ++i) t += 1;
	data[id.x] = t;
}
```

  
  
Поскольку выполняется всё это очень быстро, запустим выполнение шейдера 100 раз. Этого достаточно для того, чтобы замерить время используя Time. Также не забываем о том, что Shader.Dispatch() выполняется не сразу - он лишь кладёт в очередь операцию на выполнение. Для синхронизации данных вызовем buffer.GetData(), что запустит все накопленные команды в очереди на выполнение.   
```c#
      var tm = Time.realtimeSinceStartup;
        for (int i = 0; i < 100; i++)
            shader.Dispatch(kernelid, 64, 1, 1);
        bomputerCuffer.GetData(A);
        tm = Time.realtimeSinceStartup - tm;
```
  
Также для наглядности сравним с cpu. Здесь были допущенны некоторые хитрости: был прозведён подсчёт суммы только для одной переменной, и затраченное время умножено на размер массива (чтобы не ждать несколько минут выполнения). 
```c#
var tm = Time.realtimeSinceStartup;
        for (int i = 0; i < N*100; i++) u++;
        tm = Time.realtimeSinceStartup - tm;
        Debug.Log("On CPU time: " + tm * A.Length);
```


# Результаты
Я тестировал на видеокарте gtx1050, у которой 640 ядер Cuda.  
![Time result](/TimeTest.png)


Как и следовало ожидать, общая память оказалась самой медленной, несмотря на то что суммарное время всё-равно в сотню раз меньше, чем на cpu. Разделяемая память (кэш L1) в полтора десятка раз быстрее глобальной памяти. А вот в случае с регистровой память появляется ещё более резкий скачок - в 60 раз быстрее разделяемой памяти, или в 920 раз быстрее глобальной.  

Также стоит отметить, что время выполнения "пустой" фукции составило 40% от предыдущей - значит цикл всё-таки не оптимизировался компилятором. Следовательно, в функции теста регистровой памяти 40% времени было потрачено на перессылку данных, а на выполнение цикла из 100к итераций - только 60%.  


## Выводы
Эффективное использование разных типов памяти может существенно ускорить работу вычислительного шейдера. Обращение к элементам вычислительного буфера, расположенного в глобальной памяти, безусловно можно считать одной из наиболее затратных операций. Старайтесь по-возможности минимизировать число обращений (чтение/запись) к общей памяти, копируя значения в локальные переменные/разделяемую память и записывать результат только один раз, когда все вычисления выполнены. Также учитывайте, что объём регистров ограничен и зависит от архитектуры - и если их не будет хватать, то некоторые из них могут расположиться в более медленной памяти, что может перечеркнуть все усилия по оптимизации. 
 


